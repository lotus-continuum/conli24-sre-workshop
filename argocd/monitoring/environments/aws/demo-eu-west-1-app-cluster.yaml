opentelemetryCollectorDeployment:
  enabled: false
  helm:
    mode: deployment
    replicaCount: 1

    image:
      repository: "otel/opentelemetry-collector-contrib"

    presets:
      # Collect cluster-level metrics from the Kubernetes API server.
      clusterMetrics:
        enabled: true

      # https://opentelemetry.io/docs/kubernetes/helm/collector/#kubernetes-events-preset
      # Collect Kubernetes events.
      kubernetesEvents:
        enabled: true

      kubernetesAttributes:
        enabled: true

    resources:
      limits:
        # default is 200Mi and services often report that they cannot send
        # telemetry due to the memory limiter kicking in and refusing data
        # (message: data refused due to high memory usage)
        memory: 500Mi
    config:
      receivers:
        otlp:
          protocols:
            http:
              # Bind to 0.0.0.0 to allow for `kubectl port-forward` to work
              # This may be susceptible to denial of service attacks - CWE-1327 https://cwe.mitre.org/data/definitions/1327.html
              endpoint: 0.0.0.0:4318
        prometheus:
          config:
            global:
              scrape_interval: 15s
            scrape_configs:
              # Default collector scrape config
              - job_name: opentelemetry-collector
                scrape_interval: 10s
                static_configs:
                  - targets:
                      - ${env:MY_POD_IP}:8888

              # This config is used to find all Kubernetes endpoints that have the prometheus.io/scrape annotation.
              # In particular, it will scrape the kube-state-metrics server to provide the kube_... metrics.
              - job_name: kubernetes-service-endpoints
                # This specifies that Prometheus should discover targets based on Kubernetes endpoints.
                kubernetes_sd_configs:
                  - role: endpoints
                relabel_configs:
                  # Keep targets with prometheus.io/scrape annotation set to true
                  - action: keep
                    regex: true
                    source_labels:
                      - __meta_kubernetes_service_annotation_prometheus_io_scrape
                  # Set the scheme (http/https) based on prometheus.io/scheme annotation
                  - action: replace
                    regex: (https?)
                    source_labels:
                      - __meta_kubernetes_service_annotation_prometheus_io_scheme
                    target_label: __scheme__
                  # Set the metrics path based on prometheus.io/path annotation
                  - action: replace
                    regex: (.+)
                    source_labels:
                      - __meta_kubernetes_service_annotation_prometheus_io_path
                    target_label: __metrics_path__
                  # Set the address based on the prometheus.io/port annotation
                  - action: replace
                    regex: (.+?)(?::\d+)?;(\d+)
                    replacement: $$1:$$2
                    source_labels:
                      - __address__
                      - __meta_kubernetes_service_annotation_prometheus_io_port
                    target_label: __address__
                  # Map annotations prefixed with prometheus.io/param_ to Prometheus parameters
                  - action: labelmap
                    regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
                    replacement: __param_$$1
                  # Map service labels to Prometheus labels
                  - action: labelmap
                    regex: __meta_kubernetes_service_label_(.+)
                  # Add namespace label based on the Kubernetes namespace
                  - action: replace
                    source_labels:
                      - __meta_kubernetes_namespace
                    target_label: namespace
                  # Add service label based on the Kubernetes service name
                  - action: replace
                    source_labels:
                      - __meta_kubernetes_service_name
                    target_label: service
                  # Add node label based on the Kubernetes pod node name
                  - action: replace
                    source_labels:
                      - __meta_kubernetes_pod_node_name
                    target_label: node

      extensions:
        bearertokenauth/dash0:
          scheme: "Bearer"
          token: "auth_nkCOzkm8oBqfi90e87o7JAbyOjSZ51Sp"

      exporters:
        "otlp/dash0":
          endpoint: 'ingress.eu-west-1.aws.dash0.com:4317'
          auth:
            authenticator: bearertokenauth/dash0

      processors:
        resourcedetection:
          detectors: ["ec2"]
        resource:
          # Temporarily setting these as hard-coded values to make the demo
          # look a bit nicer, since the AWS resource detectors do not set
          # these attributes yet, see
          # https://linear.app/dash0/issue/ENG-952/collect-aws-resource-attributes
          attributes:
            - key: cloud.account.id
              value: "869266160017"
              action: insert
            - key: cloud.availability_zone
              value: eu-west-1a
              action: insert
            - key: cloud.region
              value: eu-west-1
              action: insert
            - key: cloud.platform
              value: aws_eks
              action: insert
            - key: cloud.provider
              value: aws
              action: insert

      service:
        extensions:
          - health_check
          - memory_ballast
          - bearertokenauth/dash0

        pipelines:
          metrics:
            receivers:
              - otlp
              - k8s_cluster
              - prometheus
            processors:
              - k8sattributes
              - memory_limiter
              - resourcedetection
              - resource
              - batch
            exporters:
              - otlp/dash0
