{{ if .Values.otelDemo.enabled }}
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: opentelemetry-demo
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  destination:
    namespace: otel-demo
    name: in-cluster
  project: default
  syncPolicy:
    automated:
{{- if .Values.otelDemo.autoSync }}
      selfHeal: true
{{- end }}
{{- if .Values.otelDemo.prune }}
      prune: true
{{- end }}
    syncOptions:
      - CreateNamespace=true
  source:
    chart: opentelemetry-demo
    repoURL: https://open-telemetry.github.io/opentelemetry-helm-charts
    targetRevision: {{ .Values.otelDemo.version }}
    helm:
      values: |
        prometheus:
          server:
            resources:
              limits:
                memory: 2Gi
          kube-state-metrics:
            enabled: true
        default:
          # Overriding the image repository is the intended way to re-use the official OTel demo helm chart but use
          # non-standard images (e.g. the images built from our fork of the OTel demo sources at
          # https://github.com/dash0hq/opentelemetry-demo/).
          image:
            repository: 718306648796.dkr.ecr.us-west-2.amazonaws.com/opentelemetry-demo
            tag: 1.2.2
          envOverrides:
            - name: FEATURE_FLAG_GRPC_SERVICE_ADDR
              value: 'opentelemetry-demo-featureflagservice:50053'
        components:
          adService:
            replicas: 2
          frontend:
            replicas: 1
          frontendProxy:
            resources:
              limits:
                memory: 500Mi
          featureflagService:
            enabled: true
            envOverrides:
              - name: DATABASE_URL
                value: "ecto://postgres:postgres@opentelemetry-demo-ffspostgres:5432/ffs"
          # we are using our own postgresql with persistent volume
          ffsPostgres:
            enabled: false
          kafka:
            resources:
              limits:
                # default for Kafka is 500Mi and it is frequently OOMKilled
                memory: 1Gi
        opentelemetry-collector:
          resources:
            limits:
              # default is 200Mi and services often report that they cannot send
              # telemetry due to the memory limiter kicking in and refusing data
              # (message: data refused due to high memory usage)
              memory: 500Mi
          config:
            extensions:
              bearertokenauth/dash0:
                scheme: "Bearer"
                token: {{ .Values.dash0Token }}
            exporters:
              "otlp/dash0":
                endpoint: 'ingress.eu-west-1.aws.dash0.com:4317'
                auth:
                  authenticator: bearertokenauth/dash0
            service:
              extensions:
                - health_check
                - memory_ballast
                - bearertokenauth/dash0
              telemetry:
                logs:
                  level: "debug"
              pipelines:
                logs:
                  exporters:
                    - otlp/dash0
                traces:
                  exporters:
                    - otlp
                    - otlp/dash0
                metrics:
                  receivers:
                    - otlp
                  exporters:
                    - otlp/dash0
                    - otlphttp/prometheus
---
{{ end }}